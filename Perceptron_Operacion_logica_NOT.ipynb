{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Wapsop/Redes-neuronales-1/blob/main/Perceptron_Operacion_logica_NOT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Perceptrón para operación logica NOT"
      ],
      "metadata": {
        "id": "rMrQItfd2km0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-------\n"
      ],
      "metadata": {
        "id": "7XwpeXAekXh7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Entradas para NOT: una sola columna con 0 y 1\n",
        "X = np.array([[0],\n",
        "              [1]], dtype=float)\n",
        "\n",
        "# Salidas esperadas para NOT: 1 si entra 0, y 0 si entra 1\n",
        "Y = np.array([1, 0], dtype=int)\n",
        "\n",
        "# Peso y sesgo iniciales elegidos para que haya error en x=1 al inicio (así se actualiza w)\n",
        "weights = np.array([0.5], dtype=float)\n",
        "bias = 0.5\n",
        "\n",
        "# Tasa de aprendizaje\n",
        "lr = 0.1\n",
        "\n",
        "# Épocas: cuántas veces repaso todo el conjunto\n",
        "epochs = 50\n"
      ],
      "metadata": {
        "id": "pyWxzkxLkY76"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Perceptron:\n",
        "    def __init__(self, lr, epochs, weights, bias):\n",
        "        \"\"\"\n",
        "        Guardo la tasa de aprendizaje, número de épocas,\n",
        "        el peso inicial y el sesgo para poder entrenar.\n",
        "        \"\"\"\n",
        "        self.lr = lr\n",
        "        self.epochs = epochs\n",
        "        self.weights = weights.astype(float)\n",
        "        self.bias = float(bias)\n",
        "\n",
        "    def fit(self, X, Y):\n",
        "        \"\"\"\n",
        "        Entreno el perceptrón actualizando peso y sesgo\n",
        "        con base en el error de cada ejemplo.\n",
        "        \"\"\"\n",
        "        # Orden fijo para ver primero x=1 (ahí es donde el peso puede cambiar)\n",
        "        order = np.array([1, 0])\n",
        "\n",
        "        for epoch in range(self.epochs):\n",
        "            updates = 0\n",
        "            for j in order:\n",
        "                xi, yi = X[j], Y[j]\n",
        "                y_pred = self.activation_function(np.dot(self.weights, xi) + self.bias)\n",
        "                error = yi - y_pred\n",
        "\n",
        "                if error != 0:\n",
        "                    # Si hay error, ajusto peso y sesgo\n",
        "                    self.weights += self.lr * error * xi\n",
        "                    self.bias    += self.lr * error\n",
        "                    updates += 1\n",
        "                    print(f\"[ep {epoch:02d}] x={xi[0]:.0f}, y={yi}, y_pred={y_pred} -> w={self.weights[0]:.4f}, b={self.bias:.4f}\")\n",
        "\n",
        "            if updates == 0:\n",
        "                # Si no hubo cambios en toda la época, ya convergio y se\n",
        "                # detiene la ejecucion del programa\n",
        "                print(f\"Convergió en la época {epoch} -> w={self.weights[0]:.4f}, b={self.bias:.4f}\")\n",
        "                break\n",
        "\n",
        "        print(f\"Pesos finales: {self.weights}, bias final: {self.bias}\")\n",
        "    def activation_function(self, activation):\n",
        "        \"\"\"\n",
        "        Función escalón: 1 si el valor es >= 0, de lo contrario 0.\n",
        "        \"\"\"\n",
        "        return 1 if activation >= 0 else 0\n",
        "\n",
        "    def prediction(self, X):\n",
        "        \"\"\"\n",
        "        Aplico el perceptrón a cada entrada y regreso las predicciones.\n",
        "        \"\"\"\n",
        "        sum_ = np.dot(X, self.weights) + self.bias\n",
        "        for i, s in enumerate(sum_):\n",
        "            print(f\"Input: {X[i]}, Predicción: {self.activation_function(s)}\")\n",
        "        return np.array([self.activation_function(s) for s in sum_])"
      ],
      "metadata": {
        "id": "-Sfc9Xl3kfSK"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creo y entreno el perceptrón (NOT)\n",
        "p = Perceptron(lr=lr, epochs=epochs, weights=weights, bias=bias)\n",
        "p.fit(X, Y)\n",
        "\n",
        "# Verifico la tabla de verdad\n",
        "predictions = p.prediction(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wd9H8Ejgkhky",
        "outputId": "d0db5f8f-3e2f-4e05-e9b9-79491ce8aa47"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ep 00] x=1, y=0, y_pred=1 -> w=0.4000, b=0.4000\n",
            "[ep 01] x=1, y=0, y_pred=1 -> w=0.3000, b=0.3000\n",
            "[ep 02] x=1, y=0, y_pred=1 -> w=0.2000, b=0.2000\n",
            "[ep 03] x=1, y=0, y_pred=1 -> w=0.1000, b=0.1000\n",
            "[ep 04] x=1, y=0, y_pred=1 -> w=0.0000, b=0.0000\n",
            "[ep 05] x=1, y=0, y_pred=1 -> w=-0.1000, b=-0.1000\n",
            "[ep 05] x=0, y=1, y_pred=0 -> w=-0.1000, b=0.0000\n",
            "Convergió en la época 6 -> w=-0.1000, b=0.0000\n",
            "Pesos finales: [-0.1], bias final: 2.7755575615628914e-17\n",
            "Input: [0.], Predicción: 1\n",
            "Input: [1.], Predicción: 0\n"
          ]
        }
      ]
    }
  ]
}